# -*- coding: utf-8 -*-
"""Oasis Infobyte Task 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tjBYtVr5_emRkaqyCtEXoR-DLHcuupjq

NAME : SUMEET BAFNA

OASIS INFOBYTE

DATA SCIENCE INTERNSHIP

TASK 02 : UNEMPLOYMENT IN INDIA
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

data = pd.read_csv("/content/Unemployment in India.csv")
data

# Rows And Columns
print(f"Total no of rows: {data.shape[0]}")
print(f"Total no of columns:{data.shape[1]}")

data.columns

data.info()

data.describe()

# Preprocess the data
data['Date'] = pd.to_datetime(data[' Date'], dayfirst = 'True')
data['Year'] = data['Date'].dt.year
data['Month'] = data['Date'].dt.month

# Encode categorical data
label_encoder = LabelEncoder()
data['Region'] = label_encoder.fit_transform(data['Region'])
data['Area'] = label_encoder.fit_transform(data['Area'])
data[' Frequency'] = label_encoder.fit_transform(data[' Frequency'])

#checking null values
data.isnull()

data.isnull().sum()

null_values = data.isnull().sum().sum()
print("Total no of null values",null_values)

# Remove Duplicate rows
data2 = data.drop_duplicates()
data2

# replacing null values with 0
data3 = data2.fillna(value = 0)
data3

data3.describe()

#define feature and labels
X = data3[['Region', 'Year', 'Month', ' Estimated Unemployment Rate (%)', ' Estimated Employed', ' Estimated Labour Participation Rate (%)', 'Area']]
y = data3[' Estimated Unemployment Rate (%)']

# Split the data into training and testing set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Ensure that all data is numerical and there are no missing values
print(X.dtypes)
print(y.dtypes)

# Train the model
model = RandomForestRegressor(n_estimators = 100, random_state = 42)
model.fit(X_train, y_train)

#Make Prodictions
y_pred = model.predict(X_test)
pd.DataFrame(y_pred)

# Evaluate the model
mse  = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

#Visualize the results
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred,alpha = 0.5)
plt.plot([min(y_test),max(y_test)],[min(y_test),max(y_test)],color = 'red')
plt.xlabel('Actual Unemployment Rate (%)')
plt.ylabel('Predicted Unemployment Rate (%)')
plt.title('Actual vs Predicted Unemployment Rate')
plt.show()